{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebca3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import xgboost as xgb\n",
    "\n",
    "import oc20\n",
    "import sys\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.loader.data_list_loader import DataListLoader\n",
    "\n",
    "\n",
    "sys.path.append(\"/people/d3x771/projects/chemreasoner/chemreasoner/src\")\n",
    "from nnp.oc import OCAdsorptionCalculator\n",
    " \n",
    "class GBMRegressor:\n",
    "    \"\"\"\n",
    "    Union approach for Gradient Boosting Machine uncertainty estimation\n",
    "    from https://link.springer.com/article/10.1186/s13321-023-00753-5 \n",
    "    \"\"\"\n",
    "    def __init__(self, savedir='./', lower_alpha=0.1, upper_alpha=0.9, n_estimators=100):\n",
    "        \"\"\"Initialize GBM regressors\n",
    "        Args:\n",
    "          savedir (str): Directory to save fit GBM regressors. \n",
    "                         (default: :obj:`./`)\n",
    "          lower_alpha (float): The alpha-quantile of the quantile loss function.\n",
    "                               Values must be in the range (0.0, 1.0). \n",
    "                               (default: :obj:`0.1`)\n",
    "          upper_alpha (float): The alpha-quantile of the quantile loss function. \n",
    "                               Values must be in the range (0.0, 1.0). \n",
    "                               (default: :obj:`0.9`)\n",
    "          n_estimators (int): The number of boosting stages to perform.\n",
    "                              (default: :obj:`100`)\n",
    "        \"\"\"\n",
    "        self.savedir = savedir\n",
    "        self.alpha = np.array([lower_alpha, upper_alpha])\n",
    "        self.n_estimators = n_estimators\n",
    "        \n",
    "    @property\n",
    "    def model_file(self):\n",
    "        return 'GBMRegressor.pkl'\n",
    "        \n",
    "    def update(self, embeddings, target):\n",
    "        \"\"\"Update GBM models after training epoch.\"\"\"          \n",
    "        Xy = xgb.QuantileDMatrix(embeddings, target)\n",
    "        Xy_test = xgb.QuantileDMatrix(embeddings, target, ref=Xy)\n",
    "\n",
    "        self.booster = xgb.train(\n",
    "            {\n",
    "                \"objective\": \"reg:quantileerror\",\n",
    "                \"tree_method\": \"hist\",\n",
    "                \"quantile_alpha\": self.alpha,\n",
    "                \"learning_rate\": 0.04,\n",
    "                \"max_depth\": 5,\n",
    "                \"verbosity\": 0,\n",
    "                \"disable_default_eval_metric\": True,\n",
    "            },\n",
    "            Xy,\n",
    "            num_boost_round=self.n_estimators,\n",
    "            )\n",
    " \n",
    "    def predict(self, embeddings):\n",
    "        \"\"\"Predict uncertainties for set of embeddings.\"\"\"\n",
    " \n",
    "        scores = self.booster.inplace_predict(embeddings).T\n",
    "        return np.abs(scores[0]-scores[1])/2\n",
    " \n",
    "    def _save(self):\n",
    "        \"\"\"Save GBM regressor parameters to file.\"\"\"\n",
    "        with open(os.path.join(self.savedir, self.model_file), 'wb') as f:\n",
    "            pickle.dump(self.booster, f)\n",
    " \n",
    " \n",
    "    def _load(self):\n",
    "        \"\"\"Load trained GBM regressors from file.\"\"\"\n",
    "        if os.path.isfile(os.path.join(self.savedir, self.model_file)):\n",
    "            with open(os.path.join(self.savedir, self.model_file), 'rb') as f:\n",
    "                self.booster = pickle.load(f)\n",
    "        else:\n",
    "            logging.warning(f'No trained GBM regressor found in {self.savedir}. Call GBMRegressor.update to train a model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf412be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_sample_embeddings(output_embeddings, batch):\n",
    "    \"\"\"\n",
    "    Given a dictionary comtaining model output per batch of the form:\n",
    "    {\"energy\": E_t, \"hidden_h\":h, \"hidden_m\":m, 'edge_index':edge_index}\n",
    "    \n",
    "    generate, embeddings per model input:\n",
    "    [embeddings_atomistic_graph1, embeddings_atomistic_graph2.....embeddings_atomistic_graphN]\n",
    "\n",
    "    \"\"\"\n",
    "    data = output_embeddings\n",
    "    #print(data)\n",
    "    atom_emb = data['hidden_h']\n",
    "    edge_emb = data['hidden_m']\n",
    "    energies = data['energy']\n",
    "    forces = data['forces']\n",
    "    graph_embs = []\n",
    "    for i in range(len(batch.ptr)-1):\n",
    "        idx_start = batch.ptr[i]\n",
    "        idx_end = batch.ptr[i+1]\n",
    "        #print(i, idx_start, idx_end)\n",
    "        graph_emb = atom_emb[idx_start:idx_end]\n",
    "        #print(graph_emb.size())\n",
    "        graph_emb = torch.mean(graph_emb, 0)\n",
    "        #print(graph_emb.size())\n",
    "        graph_embs.append(graph_emb)\n",
    "    return(np.array(graph_embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53e5c98b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1737115789.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    def init_model\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def init_model(dataset_type = 'OC20'):\n",
    "\n",
    "    if(dataset == dataset_type):\n",
    "        datadir= '/qfs/projects/chemreasoner/data/OC20/'\n",
    "        batch_size = 64\n",
    "        dataset = oc20.OC20(datadir, tag='200k')\n",
    "        loader = DataListLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    else:\n",
    "        print(\"UNSUPPORTED DATASET FORMAT, exiting...\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "    ads_calc = OCAdsorptionCalculator(\n",
    "        **{\n",
    "            \"model\": \"gemnet-t\",  # change to gemnet-oc-22 TODO: 06/10/2024\n",
    "            \"traj_dir\": Path(\"irrelevant\"),\n",
    "            \"batch_size\": 40,\n",
    "            \"device\": \"cpu\",\n",
    "            \"ads_tag\": 2,\n",
    "            \"fmax\": 0.05,\n",
    "            \"steps\": 300,\n",
    "        }\n",
    "    )\n",
    "    torch_calc = ads_calc.get_torch_model\n",
    "\n",
    "    uq_model = GBMRegressor(savedir=\"/people/d3x771/projects/chemreasoner/chemreasoner/uq_sample_model/\")\n",
    "    uq_model._load()\n",
    "\n",
    "    X = []\n",
    "    Y= []\n",
    "    X_descriptors = []\n",
    "    uq = []\n",
    "    num_test_batches = 2\n",
    "    for i, data_list in enumerate(loader):\n",
    "        if(i < num_test_batches):\n",
    "            batch = Batch.from_data_list(data_list)\n",
    "            print(i, len(batch))\n",
    "            print(batch)\n",
    "            batch.atomic_numbers = batch.z\n",
    "            outputs = torch_calc.predict(batch,per_image=False)\n",
    "            batch_embeddings = get_per_sample_embeddings(torch_calc.model.model_outemb, batch)\n",
    "            batch_uq = uq_model.predict(batch_embeddings)\n",
    "            for u in batch_uq:\n",
    "                uq.append(u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(uq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(uq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a04903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828a242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
